{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('titanic_train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X=df.drop(['Survived'], axis=1)\n",
    "y=df['Survived']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test=train_test_split(X,y, test_size=0.2,random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=['Age','SibSp','Fare','Parch']\n",
    "cat_features=['Sex','Embarked','Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('num_imputer',SimpleImputer()),\n",
    "        ('scaler',StandardScaler()),\n",
    "        \n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder()),\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor= ColumnTransformer(\n",
    "transformers=[\n",
    "    ('num_pipeline', num_pipeline,num_features),\n",
    "    ('cat_pipeline',cat_pipeline, cat_features)\n",
    "]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_final_pipeline=Pipeline(\n",
    "steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree_clf',DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num_pipeline',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('num_imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='mean',\n",
       "                                                                                                        v...\n",
       "                                                               presort='deprecated',\n",
       "                                                               random_state=None,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'preprocessor__num_pipeline__num_imputer__strategy': ['mean',\n",
       "                                                                                'median'],\n",
       "                          'tree_clf__criterion': ['gini', 'entropy'],\n",
       "                          'tree_clf__max_depth': [3, 4, 5, 6, 7]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up the values of hyperparameters you want to evaluate\n",
    "# IMPORTANT!!!!!!!\n",
    "# here you must use the step names as the prefix followed by two under_scores to sepecify the parameter names\n",
    "# you also need to specify the \"full path\" of the steps\n",
    "# as you can see we can even grid search parameters for preprocessing pipeline step\n",
    "param_grid = [\n",
    "    {\n",
    "        'preprocessor__num_pipeline__num_imputer__strategy': ['mean', 'median'],\n",
    "        'tree_clf__criterion': ['gini', 'entropy'], \n",
    "        'tree_clf__max_depth': [3, 4, 5, 6, 7],\n",
    "    }\n",
    "]\n",
    "\n",
    "# set up the grid search \n",
    "grid_search = GridSearchCV(tree_final_pipeline, param_grid, cv=5,\n",
    "                          scoring='accuracy',\n",
    "                          return_train_score=True)\n",
    "\n",
    "# train the model using the full pipeline\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessor__num_pipeline__num_imputer__strategy': 'median',\n",
       " 'tree_clf__criterion': 'entropy',\n",
       " 'tree_clf__max_depth': 6}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('num_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=T...\n",
       "                                                   'Pclass'])],\n",
       "                                   verbose=False)),\n",
       "                ('tree_clf',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='entropy', max_depth=6,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tree_clf_best = grid_search.best_estimator_\n",
    "tree_clf_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7653631284916201\n",
      "Precision Score : 0.8958333333333334\n",
      "Recall Score : 0.5375\n",
      "F1 Score : 0.671875\n"
     ]
    }
   ],
   "source": [
    "# To predict on new data: simply calling the predict method \n",
    "# the full pipeline steps will be applied to the testing set followed by the prediction\n",
    "y_pred = tree_clf_best.predict(X_test)\n",
    "\n",
    "# calculate accuracy, precision, recall, f1-score\n",
    "# Note: y_test is the ground truth for the tesing set\n",
    "# we have similiar score for the testing set as the cross validation score - good\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(f'Accuracy Score : {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Precision Score : {precision_score(y_test,y_pred)}')\n",
    "print(f'Recall Score : {recall_score(y_test,y_pred)}')\n",
    "print(f'F1 Score : {f1_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved! please submit the prediction csv to Kaggle.com\n"
     ]
    }
   ],
   "source": [
    "titanic_test = pd.read_csv('titanic_test.csv')\n",
    "\n",
    "y_pred_titanic = tree_clf_best.predict(titanic_test)\n",
    "\n",
    "# combine id and prediction for kaggle submission\n",
    "tree_full_pipeline_submit = pd.DataFrame({\n",
    "    'PassengerId': titanic_test['PassengerId'],\n",
    "    'Survived': y_pred_titanic\n",
    "})\n",
    "\n",
    "# generate the csv\n",
    "tree_full_pipeline_submit.to_csv('tree-full-pipeline-submit.csv', index=False)\n",
    "print('csv saved! please submit the prediction csv to Kaggle.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
